{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63b0b6b9-d2ad-4d98-b4d8-f7c0227973fb",
   "metadata": {},
   "source": [
    "## Adversarial Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9147d6f2-9d88-4ff0-a27a-844e677c73a8",
   "metadata": {},
   "source": [
    "- Many\tdifferent\tkinds\tof\tgames!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8520684-002e-401b-b1af-e61d51dd7af2",
   "metadata": {},
   "source": [
    "**Axes:**\n",
    "\n",
    "- Deterministic\tor stochastic?\n",
    "- One,\ttwo, or more players?\n",
    "- Zero\tsum?\n",
    "- Perfect information (can you see the state)?\n",
    "\n",
    "\n",
    "▪ Want algorithms for calculating a **strategy\t(policy)** which\trecommends\ta\t\n",
    "move from each state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29558f09-0b95-4cd1-b1ef-2b6fbdc9c364",
   "metadata": {},
   "source": [
    "### Deterministic Games"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcc41096-6915-45e9-9085-c5944e5a970f",
   "metadata": {},
   "source": [
    "#### Zero-Sum Games\n",
    "\n",
    "- Agents have opposite utilities (values on outcomes)\n",
    "\n",
    "- Could be a single\tvalue that one maximizes and the\tother minimizes\n",
    "\n",
    "- Adversarial,\tpure competition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46d5ee-3873-4b9c-95dd-aa82935ce55d",
   "metadata": {},
   "source": [
    "**Definition of a game:**\n",
    "\n",
    "  * initial state $s_0$\n",
    "  * $player(s)$: which player is to move in state $s$,\n",
    "  * $actions(s)$: legal actions from state $s$,\n",
    "  * $result(s,a)$: state that results,  same as $Succ(s,a)$\n",
    "  * $terminaltest(s)$: true when game is over\n",
    "  * $utility(s,p)$: payoff for player $p$ upon reaching state $s$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1133f25-e4e4-496a-845a-6a5952cd7c90",
   "metadata": {},
   "source": [
    "**Value\tof a State**\n",
    "\n",
    "The best achievable outcome (utility) from that state"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e36e6c-435d-433c-87e1-e422dba3e653",
   "metadata": {},
   "source": [
    "<img src=\"img/value.png\" width=200 height=200 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dd4e8b-ce27-481c-91be-726d0154be4f",
   "metadata": {},
   "source": [
    "### Minimax\tValues"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd2f0ff-a452-4306-8042-2251d6f87fce",
   "metadata": {},
   "source": [
    "The goal of minimax policies is to find an optimal policy against an adversary by assuming the worst case, i.e. that the opponent is doing everything to minimize the agent's utility. It is done as follows:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c8d38c6-2beb-4d31-aafc-f334d5b28a1a",
   "metadata": {},
   "source": [
    "The calculation of the `minimax(s)` value of a state $s$ can be\n",
    "summarized as\n",
    "\n",
    "$$\n",
    "\\text{minimax}(s) = \\begin{cases}\n",
    "utility(s), & \\text{if }terminaltest(s);\\\\\n",
    "\\max_{a\\in actions(s)} \\text{minimax}(result(s,a)), & \\text{if\n",
    "}player(s) \\text{ is Max};\\\\\n",
    "\\min_{a\\in actions(s)} \\text{minimax}(result(s,a)), & \\text{if\n",
    "}player(s) \\text{ is Min}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Assumes player `Min` plays optimally.  If not, `Max` will do even\n",
    "better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bcc2031-51e9-4258-890b-0bf8d7109a76",
   "metadata": {},
   "source": [
    "### Minimax Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae04002-daba-47e7-9654-2ffe7e733e1f",
   "metadata": {},
   "source": [
    "<img src=\"img/minmaxfun.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ce56ed-2f6c-4ec4-924b-cc12558ebffc",
   "metadata": {},
   "source": [
    "<img src=\"img/minimax.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e53e73-fe64-4f33-af22-29e56552544e",
   "metadata": {},
   "source": [
    "## Speeding up minimax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f93b36f5-d9aa-470b-9592-92010e617f0d",
   "metadata": {},
   "source": [
    "### Alpha-beta pruning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36649ebf-7550-4a02-863d-f27b8a358317",
   "metadata": {},
   "source": [
    "**MIN\tversion**\n",
    "- We’re\tcomputing\tthe\tMIN-VALUE\tat\tsome\tnode\tn\n",
    " - We’re\tlooping\tover\tn’s\tchildren\n",
    " - n’s\testimate\tof\tthe\tchildren’s\tmin\tis\tdropping\n",
    " - Who\tcares\tabout\tn’s\tvalue?\t\tMAX\n",
    " - Let\ta\tbe\tthe\tbest\tvalue\tthat\tMAX\tcan\tget\tat\tany\tchoice\tpoint along\tthe\tcurrent\tpath\tfrom\tthe\troot\n",
    " - If\tn\tbecomes\tworse\tthan\ta,\tMAX\twill\tavoid\tit,\tso\twe\tcan\tstop\t\n",
    "considering\tn’s\tother\tchildren\t(it’s\talready\tbad\tenough\tthat\tit\t\n",
    "won’t\tbe\tplayed)\n",
    "\n",
    "**MAX version is symmetric**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f25d34-ac79-41e2-86a0-a3708151023e",
   "metadata": {},
   "source": [
    "<img src=\"img/abfun.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08523e24-d249-414d-9396-3f7cedb1cfa9",
   "metadata": {},
   "source": [
    "<img src=\"img/alphabeta.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7c863729-bbc6-4b98-8d3d-aeecba17de5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<embed src=\"mm_prun.pdf\" type=\"application/pdf\" width=\"100%\" height=\"600px\" />"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#from IPython.display import IFrame\n",
    "#IFrame(src='mm_prun.pdf', width=500, height=500)\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "display(HTML('<embed src=\"mm_prun.pdf\" type=\"application/pdf\" width=\"100%\" height=\"600px\" />'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c91e69d-e2d1-4349-ad91-f6a42d2ac5bf",
   "metadata": {},
   "source": [
    "#### Resource\tLimits"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a5f4ec-617a-4543-9d6c-80603c4c7c12",
   "metadata": {},
   "source": [
    "**Problem:**\tIn\trealistic\tgames,\tcannot\tsearch\tto\tleaves!\n",
    "\n",
    "**Solution:**\tDepth-limited\tsearch\n",
    "\n",
    " - Instead,\tsearch\tonly\tto\ta\tlimited\tdepth\tin\tthe\ttree\n",
    " - Replace\tterminal\tutilities\twith\tan\tevaluation\tfunction\tfor\tnon-terminal\t\n",
    "positions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51bc399-bfed-4cb4-ab59-b3ddb9d1d254",
   "metadata": {},
   "source": [
    "### Expectimax\n",
    "\n",
    "Expectimax\tsearch:\tcompute\tthe\taverage\tscore\tunder\toptimal\t\n",
    "play\n",
    " - Max\tnodes\tas\tin\tminimax\tsearch\n",
    " - Chance\tnodes\tare\tlike\tmin\tnodes\tbut\tthe\toutcome\tis\tuncertain\n",
    " - Calculate\ttheir\texpected\tutilities\n",
    " - I.e.\ttake\tweighted\taverage\t(expectation)\tof\tchildren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca5c55fe-b09e-4d71-ab41-9347d72f79bc",
   "metadata": {},
   "source": [
    "<img src=\"img/expectmax.png\" width=500 height=500 />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5be29f6-2aa0-437e-81aa-1d6a7c48f9d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
